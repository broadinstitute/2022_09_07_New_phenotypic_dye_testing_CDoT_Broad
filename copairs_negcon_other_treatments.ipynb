{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modules import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from copairs.map import run_pipeline\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(asctime)s:%(name)s:%(message)s')\n",
    "logging.getLogger(\"copairs\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataframe \n",
    "Batch 1 consists of plate with standard CP dye and other plate stained with Tocris Mitobrilliant dye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1_negcon_df = pd.read_csv('gct\\\\2023_05_15_Batch1\\\\2023_05_15_Batch1_normalized_feature_select_negcon_batch.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch2_negcon_df = pd.read_csv('gct\\\\2023_05_17_Batch2\\\\2023_05_17_Batch2_normalized_feature_select_negcon_batch.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis - Plate wise with respect to other treatments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining parameters to compute map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pert_col = 'Metadata_broad_sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sameby = [pert_col]\n",
    "pos_diffby = []\n",
    "\n",
    "neg_sameby = []\n",
    "neg_diffby = [pert_col]\n",
    "null_size =10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch 1\n",
    "Since Batch1 consists of both the plates - standard CP dyes and the mitobrilliant dye, the dataframe is split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(767, 795)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch1_negcon_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check why there is difference in the number of columns and try to understand what the columns are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_negcon_df  = batch1_negcon_df.loc[batch1_negcon_df['Metadata_Plate'] == 'BR00122250']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 795)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_negcon_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mito_negcon_df = batch1_negcon_df.loc[batch1_negcon_df['Metadata_Plate'] == 'BR00122246']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383, 795)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mito_negcon_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 721)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch2_negcon_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### how come there is no addition of columns in the negcon normalized data of batch2???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_names_std = [c for c in standard_negcon_df.columns if c.startswith('Metadata')]\n",
    "feature_names_std = [c for c in standard_negcon_df.columns if not c.startswith('Metadata')]\n",
    "feats_std = standard_negcon_df[feature_names_std].values\n",
    "dframe_std = standard_negcon_df[metadata_names_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2023-07-14 11:12:22,791:copairs:Indexing metadata...\n",
      "INFO:2023-07-14 11:12:22,797:copairs:Finding positive pairs...\n",
      "INFO:2023-07-14 11:12:22,800:copairs:dropping dups...\n",
      "INFO:2023-07-14 11:12:22,806:copairs:Finding negative pairs...\n",
      "INFO:2023-07-14 11:12:22,959:copairs:dropping dups...\n",
      "INFO:2023-07-14 11:12:23,027:copairs:Computing positive similarities...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08e50bc09f5439ebe2024c0f2fccb51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2023-07-14 11:12:23,643:copairs:Computing negative similarities...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1f9756acfa445b988daaae5cd400fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2023-07-14 11:12:24,791:copairs:Building rank lists...\n",
      "INFO:2023-07-14 11:12:24,878:copairs:Computing average precision...\n",
      "INFO:2023-07-14 11:12:24,886:copairs:Computing null distributions...\n",
      "INFO:2023-07-14 11:12:25,688:copairs:Computing P-values...\n",
      "INFO:2023-07-14 11:12:25,696:copairs:Creating result DataFrame...\n",
      "INFO:2023-07-14 11:12:25,698:copairs:Finished.\n"
     ]
    }
   ],
   "source": [
    "result_std = run_pipeline(dframe_std, feats_std, \n",
    "                          pos_sameby, pos_diffby,\n",
    "                          neg_sameby, neg_diffby,\n",
    "                          null_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_std.to_csv('copairs_csv\\\\Result_Negcon_Trmts_StandardCP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copairs.map import aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_result_std = aggregate(result_std, sameby=pos_sameby, threshold=0.05)\n",
    "agg_result_std.to_csv('copairs_csv\\\\Aggregate_result_Negcon_Trmts_StandardCP.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Mito data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_names_mito = [ c for c in mito_negcon_df.columns if c.startswith('Metadata')]\n",
    "feature_names_mito = [c for c in mito_negcon_df.columns if not c.startswith('Metadata')]\n",
    "feats_mito = mito_negcon_df[feature_names_mito].values\n",
    "dframe_mito = mito_negcon_df[metadata_names_mito]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2023-07-14 11:22:02,904:copairs:Indexing metadata...\n",
      "INFO:2023-07-14 11:22:02,911:copairs:Finding positive pairs...\n",
      "INFO:2023-07-14 11:22:02,913:copairs:dropping dups...\n",
      "INFO:2023-07-14 11:22:02,915:copairs:Finding negative pairs...\n",
      "INFO:2023-07-14 11:22:03,023:copairs:dropping dups...\n",
      "INFO:2023-07-14 11:22:03,072:copairs:Computing positive similarities...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48ab0dbc0dc49f4b65605af787c3397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2023-07-14 11:22:03,684:copairs:Computing negative similarities...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253e471df0e5455eaf3818ee614d29b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2023-07-14 11:22:04,819:copairs:Building rank lists...\n",
      "INFO:2023-07-14 11:22:04,915:copairs:Computing average precision...\n",
      "INFO:2023-07-14 11:22:04,923:copairs:Computing null distributions...\n",
      "INFO:2023-07-14 11:22:05,806:copairs:Computing P-values...\n",
      "INFO:2023-07-14 11:22:05,812:copairs:Creating result DataFrame...\n",
      "INFO:2023-07-14 11:22:05,815:copairs:Finished.\n"
     ]
    }
   ],
   "source": [
    "result_mito = run_pipeline(dframe_mito, feats_mito,\n",
    "                           pos_sameby, pos_diffby,\n",
    "                           neg_sameby, neg_diffby,\n",
    "                           null_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_mito.to_csv('copairs_csv\\\\Result_Negcon_Trmts_Tocris_mitobrilliant.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_result_mito = aggregate(result_mito, sameby=pos_sameby, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_result_mito.to_csv('copairs_csv\\\\Aggregate_result_Negcon_Trmts_Tocris_Mitobrilliant.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch2 - Long stoke shifted actin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_names_act = [c for c in batch2_negcon_df.columns if c.startswith('Metadata')]\n",
    "feature_names_act = [ c for c in batch2_negcon_df.columns if not c.startswith('Metadata')]\n",
    "feats_act = batch2_negcon_df[feature_names_act].values\n",
    "dframe_act = batch2_negcon_df[metadata_names_act]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2023-07-14 11:30:00,653:copairs:Indexing metadata...\n",
      "INFO:2023-07-14 11:30:00,662:copairs:Finding positive pairs...\n",
      "INFO:2023-07-14 11:30:00,664:copairs:dropping dups...\n",
      "INFO:2023-07-14 11:30:00,670:copairs:Finding negative pairs...\n",
      "INFO:2023-07-14 11:30:00,820:copairs:dropping dups...\n",
      "INFO:2023-07-14 11:30:00,892:copairs:Computing positive similarities...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe6a53a40794c948e051c0db244ac91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2023-07-14 11:30:01,641:copairs:Computing negative similarities...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639919ab84754aed9af980753a6e9670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2023-07-14 11:30:03,001:copairs:Building rank lists...\n",
      "INFO:2023-07-14 11:30:03,144:copairs:Computing average precision...\n",
      "INFO:2023-07-14 11:30:03,153:copairs:Computing null distributions...\n",
      "INFO:2023-07-14 11:30:04,131:copairs:Computing P-values...\n",
      "INFO:2023-07-14 11:30:04,139:copairs:Creating result DataFrame...\n",
      "INFO:2023-07-14 11:30:04,140:copairs:Finished.\n"
     ]
    }
   ],
   "source": [
    "result_act = run_pipeline(dframe_act, feats_act,\n",
    "                          pos_sameby, pos_diffby, \n",
    "                          neg_sameby, neg_diffby,\n",
    "                          null_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_act.to_csv('copairs_csv\\\\Result_Negcon_Trmts_Phalloidin400LS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_result_act = aggregate(result_act, sameby=pos_sameby, threshold=0.05)\n",
    "agg_result_act.to_csv('copairs_csv\\\\Aggregate_result_Negcon_Trmts_Phalloidin400LS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining all the aggregated results for easier plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_result_std = agg_result_std.rename(columns = {'average_precision': 'average_precision_std'})\n",
    "agg_result_mito = agg_result_mito.rename(columns = {'average_precision':'average_precision_mito'})\n",
    "agg_result_act = agg_result_act.rename(columns = {'average_precision':'average_precision_act'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_result_std_subset = agg_result_std[['Metadata_broad_sample', 'average_precision_std']]\n",
    "agg_result_mito_subset = agg_result_mito[['Metadata_broad_sample', 'average_precision_mito']]\n",
    "agg_result_act_subset = agg_result_act[['Metadata_broad_sample', 'average_precision_act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.merge(agg_result_std_subset, agg_result_mito_subset, on='Metadata_broad_sample')\n",
    "combined_df  =pd.merge(combined_df,agg_result_act_subset, on='Metadata_broad_sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding metadata information to the combined_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "moa_metadata = pd.read_csv('copairs_csv\\\\LC00009948_MoA_Common_Names.csv')\n",
    "moa_metadata = moa_metadata.rename(columns = {'BRD with batch':'Metadata_broad_sample'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting BRD ID from BROAD sample name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BRD_ID(i):\n",
    "    if type(i) != float:\n",
    "        ID = i.split('-')\n",
    "        return ID[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['BRD ID'] = combined_df['Metadata_broad_sample'].map(BRD_ID)\n",
    "combined_moa_df = pd.merge(combined_df,moa_metadata, on = 'BRD ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating columns for difference in mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "combined_moa_df['std_vs_act'] = combined_moa_df['average_precision_std'] - combined_moa_df['average_precision_act']\n",
    "combined_moa_df['std_vs_mito'] = combined_moa_df['average_precision_std'] - combined_moa_df['average_precision_mito']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_moa_df.to_csv('copairs_csv\\\\PrecisionValues_with_MoA_allplates_Negcon_Trmts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
