#+title: Protocol
#+OPTIONS: ^:nil
#+PROPERTY: HEADER-ARGS+ :eval no-export

Analysis starting after the producion of illum files (all previous steps were performed by Suganya)

* Main
:PROPERTIES:
:header-args:shell: :session *main* :results output silent :exports code
:END:
** Set variables
User variables
#+begin_src shell
set USER "ALAN" # for Instance names
set USERNAME "amunozgo" # For tags
set KEY "amunozgo_cimini" # Access key created on aws
#+end_src

#+RESULTS:

Project variables
#+begin_src shell
set AWS_PROFILE "--profile imaging-platform" #Leave empty if only using one profile
set BUCKET "imaging-platform-ssf"
set PROJECT "2022_09_07_New_phenotypic_dye_testing_CDoT_Broad"
set BATCH "2023_08_02_Batch5"
#+end_src

Instance variables
#+begin_src shell
set DCP_NAME "$USER"_DCP
set BACKEND_NAME "$USER"_Backend
set ASSAYDEV_NAME "$USER"_Windows
#+end_src

Calculated variables
#+begin_src shell
set BATCH_SIZE (echo "ls $AWS_PROFILE  s3://$BUCKET/projects/$PROJECT/$BATCH/images --summarize --human-readable --recursive" | xargs aws s3 | tail -n 1)
set EBS_SIZE (echo $BATCH_SIZE | cut -f6 -d" " | sed -E "s/(.+)/ceil(\1 *1.1)/" | math)
#+end_src
** Helper functions
These will make the code below shorter. The only dependencies are aws, jq, and some basic command line tools: sed, awk, tr.

Get instance id from STDIN
#+begin_src shell
function get_instance_id
cat - | jq '."Instances"| .[] | .InstanceId' | tr -d '"'
end

#Get running instance id for a given name (e.g., ALAN_Backend)
function aws_describe_instances
echo $AWS_PROFILE "describe-instances" | xargs aws ec2
end

function get_instance_ids
# instance_name
aws_describe_instances | jq '.Reservations |
         .[] |
         .Instances |
         map(select(has("Tags"))) |
         map(select(.Tags[].Key=="Name" and .Tags[].Value=="'"$argv[1]"'")) |
         map(select(.State.Name =="running")) |
         .[] |
         .InstanceId' | tr -d '"'
end

#Get availability zone from a given instance name ir ud.
function get_value
# key value output
aws_describe_instances | jq '.Reservations  |
          .[] |
          .Instances |
         map(select(.State.Name =="running")) |
         map(select(.Tags[].Key=="'"$argv[1]"'" and .Tags[].Value=="'"$argv[2]"'")) |
         .[] | '$argv[3] | tr -d '"'
         # .Placement' | tr -d '"'
end

# Convert instance name to its id
function name_to_instance
# instance_name
get_value "Name" $argv[1] ".InstanceId"
end

# Convert instance name to its availability zone
function name_to_azone
# instance_id
get_value "Name" $argv[1] ".Placement.AvailabilityZone"
end

# Examples
# get_value "Name" "Alan_Windows" ".Placement.AvailabilityZone"
# get_instance_id "Alan_Windows"

function get_volume_id
cat - | jq ".VolumeId" | tr -d '"'
end

#+end_src

** Create instances
Base variables
#+begin_src shell
set INSTANCE_SHARED_ARGS "$AWS_PROFILE run-instances --count 1 --key-name $KEY"
set ALARM_SHARED_ARGS "$AWS_PROFILE put-metric-alarm --evaluation-periods 6 --comparison-operator LessThanThreshold --datapoints-to-alarm 6 --treat-missing-data notBreaching --statistic Average --period 10 --namespace test"
#+end_src

Helper funcitons
#+begin_src shell
function fill_instance_args
# suffix instance_type volume_size ami
echo "$INSTANCE_SHARED_ARGS --instance-type $argv[2] --block-device-mappings [{\\\"DeviceName\\\":\\\"xvdh\\\",\\\"Ebs\\\":{\\\"VolumeSize\\\":$argv[3],\\\"DeleteOnTermination\\\":false}}] --tag-specification ResourceType=instance,Tags=[{Key=User,Value=$USERNAME},{Key=Name,Value=$argv[1]}] ResourceType=volume,Tags=[{Key=User,Value=$USERNAME}] --image-id $argv[4]"
end

function fill_alarm_args
#suffix metric threshold
echo "$ALARM_SHARED_ARGS --alarm-name $argv[1] --metric-name $argv[2] --threshold $argv[3] --dimensions Name=InstanceId,Value="
end
#+end_src

Build CLI arguments for instances and their alarms
#+begin_src shell
#Instance args
set DCP_INSTANCE_ARGS (fill_instance_args $DCP_NAME m4.xlarge 8 ami-0ba60f12d0dc5fdb3)
set BACKEND_INSTANCE_ARGS (fill_instance_args $BACKEND_NAME m4.2xlarge 30 ami-0ba60f12d0dc5fdb3)
set ASSAYDEV_INSTANCE_ARGS (fill_instance_args $ASSAYDEV_NAME m4.xlarge $EBS_SIZE ami-07b1358971158dc9b)

# Alarm args
set DCP_ALARM_ARGS (fill_alarm_args $DCP_NAME NetworkIn 7000)
set BACKEND_ALARM_ARGS (fill_alarm_args $BACKEND_NAME CPUUtilization 1)
set ASSAYDEV_ALARM_ARGS (fill_alarm_args $ASSAYDEV_NAME CPUUtilization 1)
#+end_src

Deploy instances and their alarms
#+begin_src shell
# DCP

if test -z (name_to_instance $DCP_NAME)
echo $DCP_INSTANCE_ARGS | xargs aws ec2 | get_instance_id | sed -E "s/(.*)/$DCP_ALARM_ARGS\1/" | xargs aws cloudwatch;
end

# BACKEND
if test -z (name_to_instance $BACKEND_NAME)
echo $BACKEND_INSTANCE_ARGS | xargs aws ec2 | tee backend.json | get_instance_id | sed -E "s/(.*)/$BACKEND_ALARM_ARGS\1/" | xargs aws cloudwatch;
end

# AssayDev
if test -z (name_to_instance $ASSAYDEV_NAME)
echo $ASSAYDEV_INSTANCE_ARGS "--subnet-id subnet-0d87ae6d910b8b478 --security-group-ids sg-076139d4acc4b5a3c" | xargs aws ec2 | get_instance_id | sed -E "s/(.*)/$ASSAYDEV_ALARM_ARGS\1/" | xargs aws cloudwatch
end

function dns_from_name
# instance_name
aws_describe_instances | jq '.Reservations  |
          .[] |
          .Instances |
         map(select(.State.Name =="running")) | map(select(.Tags[].Key=="Name" and .Tags[].Value=="'$argv[1]'")) | .[] | .PublicDnsName' | tr -d '"'
end
#+end_src

#+begin_src shell
# echo (get_instance_id ALAN_DCP)
# echo (get_instance_id ALAN_AssayDev)
# echo (get_instance_id ALAN_Backend)
#+end_src

Now all instances should be deployed.

** Install Microsoft remote desktop
#+begin_src shell
if not type -q microsoft-remote-desktop
    brew install --cask microsoft-remote-desktop
end
#+end_src

#+RESULTS:

- Download the Remote (rdp) file
Then (sadly) open Microsoft remote desktop manuallt.

** Add storage for batch
You can check the space needed
#+begin_src shell
#+end_src
- Batch 5: 46.4 GB

*** Create and attach an EBS volume

Get availability zone
#+begin_src shell
# set ATTACH_VOLUME_ARGS "attach-volume --device xvdh --instance-id $(name_to_instance $ASSAYDEV_NAME)'' --volume-id "

# echo "$AWS_PROFILE create-volume --availability-zone $(name_to_azone $ASSAYDEV_NAME) --size $EBS_SIZE --tag-specifications ResourceType=volume,Tags=[{Key=User,Value=$USERNAME},{Key=Name,Value="$USER"_AssayDev}]" | xargs aws ec2 # | get_volume_id | sed -E "s/^/$ATTACH_VOLUME_ARGS/" | xargs aws ec2
# Automated volume attachment is not working for some reason
# echo $ATTACH_VOLUME_ARGS | xargs aws ec2

#i-007532faaefc13048
#+end_src

Run these commands after their replacement
#+begin_src shell
echo "D:"
echo "aws s3 sync  s3://$BUCKET/projects/$PROJECT/workspace/load_data_csv/ load_data_csv\\"
echo "aws s3 sync s3://$BUCKET/projects/$PROJECT/workspace/pipelines/ pipelines\\"
echo "aws s3 sync s3://$BUCKET/projects/$PROJECT/$BATCH/illum/ illum\\$BATCH\\"
echo "aws s3 sync s3://$BUCKET/projects/$PROJECT/$BATCH/images/ $BATCH\\images\\"
#+end_src

*** Edit CSV for windows
I plan to move all the Windows section to a graphical Ubuntu environment. For now, to use GNU utils I installed cywin (https://www.cygwin.com/install.html).

#+begin_src shell
sed -i 's/\/home\/ubuntu\/bucket\/projects\/\S+?\//D:\\/g' load_data_with_illum.csv

sed -i 's/\//\\/g' load_data_with_illum.csv
#+end_src

**** Edit assaydev.pipe
**** Upload to aws
#+begin_src shell
echo "aws s3 cp D:\\\pipelines\\\\"$BATCH"\\\assaydev.cppipe s3://$BUCKET/projects/$PROJECT/workspace/pipelines/$BATCH/assaydev.cppipe"

#+end_src

*** Run DevAssay
**** Configure Distributed Cell Profiler.
**** Configure Batch File
**** Run segmentation for a subset of the data
**** Stitch images into one
